{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Sparkify Analytics \n",
    "\n",
    "<b>Sparkify</b> is an international media services provider. It's primary business is to build an <b>audio streaming</b> platform that provides music, videos and podcasts from record labels and media companies  \n",
    "\n",
    "## Challenge\n",
    "\n",
    "Sparkify wants to better serve its users and thus needs to analyze the data collected on songs and user activity on their music streaming app. The analytical goal is to understand what songs users are listening to  \n",
    "\n",
    "## Architecture \n",
    "\n",
    "Currently, the data resides in a directory of CSV logs on user activity on the app  \n",
    "This architecture doesn't provide an easy way to query the data  \n",
    "\n",
    "## Analytics goals \n",
    "\n",
    "Sparkify wants to create a <b>Cassandra database</b> with tables designed to optimize queries on song play analysis. The main idea is to create a <b>(OLAP-oriented) database schema</b> to support their analytical needs and <b>ETL pipeline</b> to populate it from their logs  \n",
    "Below is a 2-step process, where first all the CSV files are aggregated into a single CSV file and second the tables are created and populated according to the queries the data is modeled after"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Part I. ETL Pipeline for pre-processing the files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<b>The following code must be run in order to pre-process the files</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages\n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create constants for the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# define constants\n",
    "EVENT_FOLDER = '/event_data'\n",
    "EVENT_FILE = 'event_datafile_new.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create a list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + EVENT_FOLDER\n",
    "\n",
    "# create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "    #print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Process the files to create the data file csv that will be used for Apache Cassandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8056\n"
     ]
    }
   ],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = []\n",
    "\n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "    # reading csv file\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile:\n",
    "        # creating a csv reader object\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)\n",
    "\n",
    "        # extracting each data row one by one and append it\n",
    "        for line in csvreader:\n",
    "            #print(line)\n",
    "            full_data_rows_list.append(line) \n",
    "\n",
    "# uncomment the code below if you would like to get total number of rows \n",
    "print(len(full_data_rows_list))\n",
    "# uncomment the code below if you would like to check to see what the list of event data rows will look like\n",
    "#print(full_data_rows_list)\n",
    "\n",
    "# create a new event data csv file called event_datafile_new that will be used to insert data into the Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open(EVENT_FILE, 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "\n",
    "    for row in full_data_rows_list:\n",
    "        # if the row does not include an artist then discard it\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open(EVENT_FILE, 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Apache Cassandra Analytical Process\n",
    "\n",
    "<b>The CSV file titled <font color=red>event_datafile_new.csv</font> located within the Workspace directory is now available</b>  \n",
    "\n",
    "It contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 1. Run the following code to perform the initial setup in order to use Apache Cassandra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the cluster\n"
     ]
    }
   ],
   "source": [
    "# create a connection to a Cassandra instance on a local server (127.0.0.1)\n",
    "from cassandra.cluster import Cluster\n",
    "\n",
    "try:\n",
    "    cluster = Cluster(['127.0.0.1'])\n",
    "    # create a session to establish a connection and begin executing queries\n",
    "    session = cluster.connect()\n",
    "    # report success\n",
    "    print(\"Successfully connected to the cluster\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create a Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace successfully created\n"
     ]
    }
   ],
   "source": [
    "# create a keyspace\n",
    "try:\n",
    "    session.execute(\" \\\n",
    "        CREATE KEYSPACE IF NOT EXISTS udacity \\\n",
    "        WITH REPLICATION = \\\n",
    "            { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\")\n",
    "    # report success\n",
    "    print(\"Keyspace successfully created\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set the Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyspace set successfully\n"
     ]
    }
   ],
   "source": [
    "# set current keyspace to the keyspace created above\n",
    "try:\n",
    "    session.set_keyspace('udacity')\n",
    "    # report success\n",
    "    print(\"Keyspace set successfully\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<b>Now we are ready to create tables to run queries</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## The queries must answer the following 3 questions of the data\n",
    "\n",
    "<b>1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4</b>\n",
    "\n",
    "\n",
    "<b>2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182</b>\n",
    "    \n",
    "\n",
    "<b>3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'</b>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 2. How should we model this data to run query 1 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`Give me the artist, song title and song's length in the music app history that was heard during sessionId = 338, and itemInSession = 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since your data is looking for the `sessionId` and `itemInSession`, let's start with that. Their combination uniquely identifies a song that was heard in the dataset. They are good candidates for the <b>primary key</b>  \n",
    "\n",
    "The `sessionId` by itself is enough to spread the data evenly across nodes so it will be the <b>partition key</b>, `itemInSession` will be a <b>clustering column</b>\n",
    "\n",
    "`artist`, `song title` and `song's length` are additional columns in the table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table songs_by_session successfully deleted\n",
      "Table songs_by_session successfully (re)created\n"
     ]
    }
   ],
   "source": [
    "# drop the table if already exists\n",
    "query = \"DROP TABLE IF EXISTS sessions_history\"\n",
    "\n",
    "# create the songs_by_session table\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_session successfully deleted\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_by_session \"\n",
    "query = query + \"(session_id int, item_in_session int, artist text, title text, length float, \"\n",
    "query = query + \"PRIMARY KEY (session_id, item_in_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_session successfully (re)created\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Insert data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data inserted\n"
     ]
    }
   ],
   "source": [
    "with open(EVENT_FILE, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # insert data into table\n",
    "        query = \"INSERT INTO songs_by_session (session_id, item_in_session, artist, title, length)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s)\"\n",
    "\n",
    "        session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n",
    "\n",
    "print(\"Data inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Validate the model with the query  \n",
    "`SELECT artist, title, length FROM songs_by_session WHERE session_id=338 AND item_in_session=4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithless Music Matters (Mark Knight Dub) 495.30731201171875\n"
     ]
    }
   ],
   "source": [
    "# run the query against the model\n",
    "query = \"SELECT artist, title, length \\\n",
    "    FROM songs_by_session \\\n",
    "    WHERE session_id=338 AND item_in_session=4\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print (row.artist, row.title, row.length)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<b>Success, It worked !!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 3. How should we model this data to run query 2 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`Give me the name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since your data is looking for the `userId` and `sessionId`, let's start with that. Unfortunately their combination does not uniquely identify a song that was heard in the dataset. Moreover, the `artist` and `song` must be sorted by `itemInSession`.  \n",
    "So a combination of these 3 fields is a good candidate for the <b>primary key</b>  \n",
    "\n",
    "The `userId` by itself is enough to spread the data evenly across nodes so it will be the <b>partition key</b>, `sessionId` and `itemInSession` will be <b>clustering columns</b> \n",
    "\n",
    "`artist`, `song title`, `first name` and `last name` are additional columns in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table songs_by_user_session successfully deleted\n",
      "Table songs_by_user_session successfully (re)created\n"
     ]
    }
   ],
   "source": [
    "# drop the table if already exists\n",
    "query = \"DROP TABLE IF EXISTS songs_by_user_session\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user_session successfully deleted\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n",
    "\n",
    "# create the songs_by_user_session table\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_by_user_session \"\n",
    "query = query + \"(user_id int, session_id int, item_in_session int, artist text, title text, first_name text, last_name text, \"\n",
    "query = query + \"PRIMARY KEY ((user_id, session_id), item_in_session))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user_session successfully (re)created\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Insert data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(EVENT_FILE, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # insert data into table\n",
    "        query = \"INSERT INTO songs_by_user_session (user_id, session_id, item_in_session, artist, title, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        session.execute(query, (int(line[10]), int(line[8]), int(line[3]), line[0], line[9], line[1], line[4]))\n",
    "\n",
    "print(\"Data inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Validate the model with the query  \n",
    "`SELECT SELECT artist, title, first_name, last_name FROM songs_by_user_session WHERE user_id = 10 AND session_id = 182 ORDER BY session_id, item_in_session ASC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Down To The Bone Keep On Keepin' On Sylvie Cruz\n",
      "Three Drives Greece 2000 Sylvie Cruz\n",
      "Sebastien Tellier Kilometer Sylvie Cruz\n",
      "Lonnie Gordon Catch You Baby (Steve Pitron & Max Sanna Radio Edit) Sylvie Cruz\n"
     ]
    }
   ],
   "source": [
    "# run the query against the model\n",
    "query = \"SELECT artist, title, first_name, last_name \\\n",
    "    FROM songs_by_user_session \\\n",
    "    WHERE user_id = 10 AND session_id = 182 \\\n",
    "    ORDER BY item_in_session ASC\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print (row.artist, row.title, row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<b>Success, It worked !!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## 4. How should we model this data to run query 3 ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "`Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "Since your data is looking for the `title`, let's start with that. Unfortunately the title of a song by itself does not uniquely identify a user in the dataset.  \n",
    "So a combination of these 2 fields is a good candidate for the <b>primary key</b>  \n",
    "\n",
    "The `title` by itself is enough to spread the data evenly across nodes so it will be the <b>partition key</b>, `userId` will be a <b>clustering column</b> \n",
    "\n",
    "`first name` and `last name` are additional columns in the table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Create the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table songs_by_user successfully deleted\n",
      "Table songs_by_user successfully (re)created\n"
     ]
    }
   ],
   "source": [
    "# drop the table if already exists\n",
    "query = \"DROP TABLE IF EXISTS songs_by_user\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user successfully deleted\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n",
    "\n",
    "# create the songs_by_user table\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_by_user \"\n",
    "query = query + \"(title text, user_id int, first_name text, last_name text, \"\n",
    "query = query + \"PRIMARY KEY (title, user_id))\"\n",
    "\n",
    "try:\n",
    "    session.execute(query)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user successfully (re)created\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Insert data into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open(EVENT_FILE, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        # insert data into table\n",
    "        query = \"INSERT INTO songs_by_user (title, user_id, first_name, last_name)\"\n",
    "        query = query + \" VALUES (%s, %s, %s, %s)\"\n",
    "\n",
    "        session.execute(query, (line[9], int(line[10]), line[1], line[4]))\n",
    "\n",
    "print(\"Data inserted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Validate the model with the query  \n",
    "`SELECT first_name, last_name FROM songs_by_user WHERE title = 'All Hands Against His Own'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacqueline Lynch\n",
      "Tegan Levine\n",
      "Sara Johnson\n"
     ]
    }
   ],
   "source": [
    "# run the query against the model\n",
    "query = \"SELECT first_name, last_name \\\n",
    "    FROM songs_by_user \\\n",
    "    WHERE title = 'All Hands Against His Own'\"\n",
    "\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "for row in rows:\n",
    "    print (row.first_name, row.last_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "<b>Success, It worked !!</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table songs_by_session successfully deleted\n",
      "Table songs_by_user_session successfully deleted\n",
      "Table songs_by_user successfully deleted\n"
     ]
    }
   ],
   "source": [
    "query1 = \"DROP TABLE IF EXISTS songs_by_session\"\n",
    "query2 = \"DROP TABLE IF EXISTS songs_by_user_session\"\n",
    "query3 = \"DROP TABLE IF EXISTS songs_by_user\"\n",
    "\n",
    "try:\n",
    "    session.execute(query1)\n",
    "    # report success\n",
    "    print(\"Table songs_by_session successfully deleted\")\n",
    "    session.execute(query2)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user_session successfully deleted\")\n",
    "    session.execute(query3)\n",
    "    # report success\n",
    "    print(\"Table songs_by_user successfully deleted\")\n",
    "except Exception as e:\n",
    "    # report error if any\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
